Database: 



#***Bản chất SSMS
Stored database -> internal schema(internal level) -> conceptual schema -> many external views for each end user
=> internal schema là file lưu key-val; conceptual level là các bảng và query, external view là view thấy data trong SQL, xem part of data.



# Basic:
-> Định nghĩa DB chuẩn: là shared collection of related data that is organized so that it can be easily accessed, managed and updated. Database giúp các ứng dụng chia sẻ database cho nhau, minimize redundancy. Database là phiên bản tốt của file management system vì nó access data dễ và tiện, chia sẻ linh hoạt.
Data -> DBMS -> Database / Metadata -> tức DB lưu cả metadata

Số lượng primary key trong table chỉ có thể là 0 or 1, 1 table có thể k có primary key được, hệ thống tự hiểu. Số lượng foreign key thì >= 0.

-> Thuật ngữ:
DataModel: Về mặt concept kiểu type <type name> = record
Schema: Rõ hơn của model về khi cấu trúc data structure cụ thể rồi type student = record
Instance: Từng table, là giá trị của schema.
=> Do đó ít khi dùng thuật ngữ data model mà dùng schema đê mô tả dữ liệu.
Có 3 vai trò user quan trọng: admin là người toàn quyền, designer là người thiết kế lúc tạo, end-user là người sử dụng query

Record hay tuple là 1 single row trong bảng. Relation data lưu dưới dạng bảng. Cardinality là số lượng record của 1 relation. Degree là số lượng attribute của relation hay field trong bảng. Entity là đang nói về 1 field trong số các field.
VD: R(A1, A2, A3,...) thì R là relation name và mỗi cái tuple là dạng t=<v1,v2,v3,...>
Mỗi tuple là 1 ordered list. KH relation thg là R, Q. KH tuple là r,t. 
Mỗi attr có 1 domain VD dom(A1) = dom(age) = {2,9} miền giá trị
Database Object là các defiend object trong DB, nó chỉ chung.
Relation: Attribute - Record; Table: Column(Field), Row(Tuple)



#***Cơ chế lưu database lưu trong storage
Data được lưu trên đĩa cứng or mainmem như bth. Vc truyền data giữa đĩa cứng và main mem thông qua units of disk blocks, mỗi cái có size từ 4-8KB. 

Disk defragmentation trong máy tính nếu right click properties sẽ thấy ổ đĩa chia theo kiểu so le:
xanh trắng xanh xanh xanh trắng xanh xanh xanh
=> VD các vùng màu xanh là ứng dụng chạy. Đáng lẽ nó phải kín xanh hết nhưng vẫn dôi ra các vùng màu trắng là do ứng dụng dùng xong thì bộ nhớ giảm đi làm dôi ra các phần thừa. Về sau các ứng dụng dùng thêm vùng nhớ thì nó append dùng tiếp vào các phần đằng sau vì các vùng trắng k đủ thành ra 1 ứng dụng nhưng lại lưu ở nhiều vùng nhớ rời rạc, địa chỉ rời rạc làm nó truy cập bị chậm. Các phần mêm disk optimization chính là cơ chế rearrange lại các vùng nhớ làm cho ứng dụng sau khi cài và sử dụng sẽ lưu về các vùng liên tiếp nhau trên disk.

-> Cơ chế: Khi ứng dụng chạy sẽ lưu theo các disk block, giả sử mỗi cục [] là 1 block, mỗi lần read write query DB sẽ access theo 1 lượng memory page, giả sử ở đây memory page cho query tới 2 block, ứng dụng ta chạy có màu đỏ:
[đỏ][trắng][trắng][đỏ][trắng][đỏ][trắng][trắng]...
[         ]       [         ][         ]
=> Do ứng dụng được lưu rời rạc trên đĩa làm nó tốn rất nhiều query để lấy được data. VD như trên thì các query bị thừa khi query cái trắng là vùng nhớ trống or vùng nhớ của 1 ứng dụng khác k cần thiết => ứng dụng disk optimization cơ chế sẽ đưa các vùng nhớ của cùng ứng dụng về sát lại nhau:
[đỏ][đỏ][đỏ][đỏ][trắng][trắng][trắng]...
[      ][      ]
=> read write I/O chơi đúng 2 memory page query là xong. 



# Storage
-> Có 2 cách lưu data trên database lưu vật lý: primary file organization và secondary file organization.
--> Primary file organization có 3 PP là Unorderd Records, Orderd Records và Hash file. Tùy ứng dụng select hay update nhiều mà dùng kiểu khác nhau
--> Secondary file organization là PP đánh index để truy vấn hiệu quả chính là thứ dùng trong database. Có nhiều data structure lưu index DS tùy loại DBMS.

-> Sparse index và dense index



#***Hiểu về index trong db
-> Clustered index và non-clustered index:
- Khi tạo PRIMARY KEY thì cũng là đánh chỉ mục clustered index chỉ có 1, các hàng k được trùng dữ liệu với nhau. 
Nó giúp search nhanh hơn nhưng insert delete chậm hơn. Bản chất nó sắp xếp lại dữ liệu thực tế của bảng theo chỉ mục, thành các khối chứa đúng data liền nhau trên bộ nhớ thì 1 page table nó truy cập nhiều hơn

- UNIQUE KEY có default là NON_CLUSTERED và được NULL. Nó có thể giúp tìm kiếm nhanh hơn nhưng update vẫn k chậm lắm vì update chỉ thêm 1 trường index nên k đáng kể, và nó cũng tốn thêm bộ nhớ. Bản chất nó tạo 1 node mới trên cây trỏ tới address thực tế, nhưng k sắp xếp lại disk nên hiện tương data sole có thể làm page table k query tối ưu

Index cũng làm mọi query liên quan đến trường được đánh index nhanh hơn. VD 2 bảng join với nhau 1 trường thì đánh index trường đó ở 1 trong 2 bảng sẽ giúp query join nhanh hơn. K nên đánh chỉ mục khi các bảng có kích thước nhỏ, hay được cập nhập dữ liệu thường xuyên hoặc các cột có nhiều giá trị NULL. 

-> Khác biệt của multicolumn index và multiple indexes:
VD: age, name, id ta đánh 3 non clustered index độc lập hay đánh 1 index cho cả 3 trường khác nhau ntn

--> Nếu đánh mỗi trường 1 index, ta có thể search tốc độ nhanh theo từng trường riêng biệt. Nếu search theo cả 3 trường thì vc đánh index từng trường có thể k làm cho tốc độ nhanh hơn mà chỉ search nhanh 1 trường trong đó thôi.
--> Nếu đánh multicolumn index cho cả (age, name, id) thì tốc độ search (age) or (age, name) or (age, name, id) cho tốc độ nhanh hơn bth. Nhưng nếu chỉ search trường age cho tốc độ k nhanh bằng đánh chỉ 1 index cho age. Còn nếu search theo id or name riêng thì sẽ chậm hơn nh so với đánh lẻ từng index.

-> Có nhiều cấu trúc dữ liệu lưu index: 
B+ tree là PP lưu index db bằng balance tree duyệt từ root tới leaf nhanh, range query ok; Còn hash data structure lưu index k nên use với range query

Khi đánh chỉ mục, ta cứ hiểu là có thể refer đến các mục trong memory trực tiếp mà k cần duyệt lần lượt trên disk:
Address table: FM -> giả sử đánh index trường gender male hay female
Vùng nhớ file: FFFMFMFMFFFFMMM
Tuy nhiên có TH data đánh so le làm tốc độ nó k đổi: FMFMFMFMF -> VD mỗi mem page chơi 2 block, mỗi block 1 data thì đánh chỉ mục index tốc độ y hệt như duyệt tuần tự
=> Nch là disk defragmentation sx lại vùng nhớ cả ứng dụng(hard disk), index là truy cập nhanh data inside ứng dụng, clustered có sx lại vị trí lưu data và non-clustered thì tạo bảng mới reference đến địa chỉ gốc của data



# Câu lệnh index:
Mở table -> vào indexes trong SSMS sẽ thấy các indexes tạo ra
Vc tối ưu chỉ mục sẽ giúp xác định vị trí của dữ liệu cần tìm. VD tìm 1 thứ bình thường sẽ duyệt hết vài triệu record trong bảng nhưng khi có index thì chỉ cần tìm vài trăm

K thể đánh 2 index cùng trường. Các trường được đánh index có thể dùng where tìm kiếm tốc độ cao. 1 table ta chỉ được tạo ra 1 cái index, cái index đó có thể đánh được nh trường

Pb: clustered index k copy mới mà nó dùng data cũ và sắp xếp lại vùng nhớ, còn materialized view thì copy hoàn toàn

-> Có lệnh USING {BTREE|HASH} để xác định dùng index với DS nào

-> Các câu lệnh tìm 1 giá trị mà khác giá trị nào trong DB thì nên tránh trong thực tế vì nó k tận dụng được index, vì nó tìm các giá trị bằng giá trị đó và loại bỏ đi. 
VD nếu ta cần tìm người có ngày sinh khác 1/4/2000. Nếu ta đánh index cho ngày sinh bằng BTree thì nên query kiểu tìm người có ngày sinh > 1/4/2000 hoặc < 1/4/2000 (vì BTree rất mạnh với range query) => tốc độ sẽ nhanh hơn vì nó lấy 1 bên của Tree là xong. Đương nhiên ở TH này dùng BTree thì nó vẫn duyệt qua các bản ghi khác 1/4/2000 để lấy ra nhưng nếu như có rất nhiều bản ghi cùng ngày 1/4/2000 thì C2 sẽ giúp kp duyệt qua tất cả bản ghi đó mà bỏ qua luôn nên nhanh hơn.



#***Cơ chế xử lý query của DB Server
Query của user --Parser--> Relational Algebric(RA) --Optimizer--> Query execution plan
Optimizer dùng equivalence transformation để chuyển sang code tương đương nhưng tốc độ nhanh hơn: Ưu tiên chạy select và projection trước, logic và join thực hiện sau cùng khi data đã được lọc nhỏ r.

VD: R1 có n phần tử, R2 có m phần tử:
R1 join R2 thì số lần duyệt = n + n x m tức duyệt R1 n lần, duyệt R2 n x m lần
R2 join R1 thì duyệt R1 n x m lần, duyệt R2 m lần tức m + n x m
=> Nếu n << m thì tốc độ join của TH1 nhanh hơn TH2 rất nhiều. Đó là công việc của optimizer.



# Algebric expression của 1 câu lệnh SQL chỉ là 1 cách khác để viết ra câu lệnh ra giấy
-> Union, Intersect, Difference, CProduct, Selection, Projection, Rename, Inner Join, Division, Left Outer join, Right Outer join, Aggregation, Natural join, Full Outer join chắc là nó kết hợp left và right outer join ngoe ra 2 bên thôi.
=> Ký hiệu của Natural Join là A |X| B. Khi viết INNER JOIN thì cũng chỉ là NATURAL JOIN thay đổi điều kiện thì viết thêm điều kiện nhỏ ở bên dưới phải ký hiệu. VD: A |X|<a>10> B. INNER JOIN cũng gọi là theta join

-> Equivalence transformation nhưng faster:
VD: SELECT * FROM R1 WHERE R1.A=X AND R1.C > Y 
=> o<R1.A=X ^ R1.C>Y>(R1)
VD: SELECT St.* FROM Student St, Subject S, Enrollment E WHERE St.StudenId = E.StudenId AND E.Sid = S.Sid AND Sname = 'Database' AND grade = 'A' 
=> C1: n<St.*>(o<sname='Database'^grade='A'>(St*E*S)) -> tức là natural join 3 cái r check điều kiện lồng dần dần
C2: n<St.*>(St*(o<grade='A'>E)*(o<sname='Database'>S))
=> Nhìn chung 2 cách tốc độ ngang nhau nhưng nếu kích thước của (o<grade='A'>E) nhỏ hơn đáng kể so với (E) thì cách 2 nhanh hơn cách 1.
=> Error: CHÚ Ý khi dùng NATURAL JOIN phải đúng thứ tự A*B*C thì A và B có điểm chung, xong cả 2 có điểm chung với C mới được nha

VD: R1 có n phần tử, R2 có m phần tử:
R1 join R2 thì số lần duyệt = n + n x m tức duyệt R1 n lần, duyệt R2 n x m lần
R2 join R1 thì duyệt R1 n x m lần, duyệt R2 m lần tức m + n x m
=> Nếu n << m thì tốc độ join của TH1 nhanh hơn TH2 rất nhiều => optimizer cần chuyển đổi như v và rất nhiều các type khác tương tự trong slide.
VD: o<O1>(E1 x E2) = E1 |X|<O1>(E2) thì cách 1 sẽ select từng cái tạo cartesian product r dùng select cái thỏa mãn. Cách 2 thì check từng cái thỏa mãn thì lấy thì cách 2 nhanh hơn và rẻ hơn.
VD: E1|X|(E2|X|E3) = (E1|X|E2)|X|E3 nếu E2|X|E3 << E1|X|E2 thì bên trái rẻ hơn

-> Để convert sang relational algebric các toán tử đã học buộc phải quy về vc join chúng và dùng toán từ difference nhiều.
VD: SELECT Name FROM BORROWER as B WHERE NOT EXIST ( SELECT * FROM BOOK_LOANS as BL WHERE B.CardNo=BL.CardNo)
=> Project(name)((S(card_no)(b)-S(card_no(BL)) join B) 
Natural Join dùng rất mạnh trong các bài tập khi cố muốn lấy 1 phần cái gì phức tạp thì biến đổi cùng tên 1 trường để mất các giá trị k cần thiết r natural join nó.

VD: select E.fname, E.lname, E.address from employee as E NATURAL JOIN works_on as W NATURAL JOIN project as P and PLocation = “Houston” and not exist (select*From Dept_Location Where DNumber = E.DNo and DLocation = “Houston”)
=> Project(E.fname, E.lname, E.address)(Project(DNO)(S(PLocation='Houston')(E |><| W |><| P)) - Project(DNO)(S(DLocation='Houston')(Dept_Location)) |><| (E|><|W|><|P))

Task của optimizer:
-> Exec alg of RA: dùng các operator để thực hiện thuật toán optimize
--> 1 Pass Operators: là các operator lấy trực tiếp => duyệt table tìm data thỏa mãn add vào kết quả thì có thể duyệt tuần tự or duyệt theo index
--> Multi Pass Operators: giải quyết các phép join
---> Sort-merge JOIN: file chứa data phải sorted từ trước, và nó sẽ merge và join lại (thực hiện câu lệnh join) và đọc từng data block
---> Partition-hash JOIN: Hash từng bảng quan hệ lại trước r join lần lượt lấy giá trị
--> Execution Strategy: Sau khi nó tạo ra các case rồi sẽ có 1 tree các bước có thể thực hiện.
---> Materialization: thực hiện từ lá đến ngọn và trở thành input để thực hiện về ngọn, các node internal lại lưu result và trở thành input nên tốn chi phí ghi vào disk cho nó
---> Pipelining: thành chuỗi queue thực hiện lần lượt và kết quả pass lần lượt qua, nó phải cấu trúc lại thuật toán cho phép nhận stream of input và output

-> Cost estimation: phụ thuộc vào số block, tuple, distinct value



# Replica
Replication management dùng master copy và các slave là secondary copy theo quan hệ 1-m hay n-m. Mô hình này dùng trong nhiều TH như mở rộng data để tăng hiệu suất khi mà đọc nhiều ghi ít, backup database cũng dùng replica lưu bản copy, đánh index hay tạo view cũng là dùng replica. Virtual k lưu trong database nhưng materialized thì có. Vc dùng materialized view chính là dùng secondary copy nên cần viết update thủ công cho nó.
VD: dùng mở rộng database với quan hệ m-n thì 1 update 1 master là hàng loạt copy phải được update nhưng phải đảm bảo về delay để mọi DB read đồng bộ ngay lập tức



# ACID
ACID stands for atomicity, consistency, isolation, and durability
-> Tính Durability trong ACID tức là 1 khi đã thành công là trạng thái được bảo toàn và k thể undone, kể cả bị sập điện ngay sau khi thành công
-> Tính Isolation trong ACID là các câu lệnh bên trong transaction được độc lập với các câu lệnh khác bên trong transaction đó.
-> Tính nhất quán consistency tức là data lưu trữ phải hợp lệ



#***Cơ chế lock Transaction trong DB
-> Cơ chế lock trong SQL:
Dùng shared lock (LS) xử lý đọc, Exclusive lock(LX) xử lý ghi. 2 cái này cho phép bao nhiêu người đọc hay ghi cùng 1 lúc. 
Mặc định trong db: Vừa có người ghi thì k thể đảm bảo read sẽ được giá trị mới nhất; Db auto lock khi W+W cùng 1 nơi

Lock trong db được thiết kế để luôn chuẩn và tối ưu. VD A chuyển tiền cho B thì phải lock A trước khi dùng A, lock B ngay trước khi dùng B để tối ưu tg lock là đúng nhất. Nếu lock B ngay từ đầu thì k cần thiết vì thay đổi A chưa thay đổi B thì k tối ưu. Sau khi thay đổi A xong k được unlock A luôn mà vẫn phải chờ đến cuối vì biết đâu có 1 trans nào đó dùng A hoàn thành trong lúc đổi B, nhưng B gặp lỗi bị hoàn tác thì trans cũ kia bị sai.
=> Gọi là phantom transaction. Lỗi này thg gặp khi 1 trans ngắn, 1 trans dài lồng nhau.

-> Isolation level là các mức độ sử dụng lock. Thông thường db luôn tự lock mặc định, nhưng nếu ta muốn custom như nào thì có thể thay đổi.

4 trạng thái lỗi khi thực hiện 1 tx trong db (nên nhớ là đang xét 1 tx có đọc, có ghi):
Dirty Reads: trans 1 đang update nhưng chưa committed, trans 2 vào read uncommitted data đó. Về sau trans 1 báo lỗi và ROLL BACK thì trans 2 lại thao tác với data lỗi đó nên sai.
Lost Update: trans 1 update a = 100, trans 2 update a = 120 đồng thời. Thì giả sử tx2 thành công thì tx1 đã biến mất
Non-repeatable Reads: trans 1 read title 2 lần liên tiếp; trans 2 write vào title và lệnh write của trans 2 xen đúng giữa 2 lệnh read của trans 1 => trans 1 read 2 lần liên tiếp nhưng lại cho kết quả khác nhau nên là non-repeatable
Phantom Reads: trans 1 thực hiện 2 lần cùng 1 lệnh read có điều kiện trên 1 tập hợp nhiều bản ghi và tx 2 update dữ liệu đó sao cho lần 2 tx 1 đọc lại ra giá trị khác vì ví dụ có thêm dữ liệu mới hoặc mất bớt dữ liệu cũ vì k thỏa mãn điều kiện chẳng hạn. Nó khác non-repeatable update ở chỗ là quan sát sự thêm bớt của các bản ghi trong 1 tập hợp

VD Repeatable Read:
Trans1: dùng xong B, Read/Write và lock(A), Read/Write và commit(A), dùng tiếp B
Trans2: Write vào B, Write vào A
=> Chống Non repeatable read vì Trans2 lúc write vào A trong lúc trans 1 thao tác với A bị cấm. K chống Phantom Read vì trans2 write vào B được làm 2 vị trí trong Trans 1 cùng truy cập vào B cho kết quả khác nhau => hay

2 phase locking: thực hiện 1 tx sẽ lock từ từ đến khi cần dùng từng cái, đạt đỉnh sẽ release lock từ từ khi k cần dùng nữa
strict 2 phase locking: tương tự lock từ từ, nhưng bước cuối chờ tx hoàn thành cả mới release hết 1 thể. Làm v mới ngăn được dirty read và non-repeatable read.

4 level isolation:
Read Uncommitted: Chả làm gì cả và read hay write gì cứ tự nhiên lấy vào đúng thời điểm được gọi. Nó ăn cả 4 lỗi trên vì chả lock gì cả. Mới uncommitted đã read r
Read Committed: Đây là level default của 1 transaction nếu ta k làm gì thêm. Mặc định 1 trans k thể đọc dữ liệu từ 1 trans khác đang trong quá trình cập nhập dữ liệu mới mà phải đợi hoàn tất committed, tức là nó dùng lock on write. Các trans phải chờ nhau tuần tự. Chống được dirty reads thôi. K chống được non-repeatable vì nó chỉ khóa khi ghi chứ k khóa khi đọc. Committed r mới được read
Repeatable Read: Là lock cả read và write ở đầu cuối mỗi lệnh đọc và ghi. Là kiểu dùng phổ biến nhất, nó chỉ k chống được phantom read.
Serializable: cấp cao nhất chống mọi thứ. Khóa tất ở đầu cuối mỗi trans, thực hiện thành tuần tự cmnl. Thành chuỗi hoàn toàn cho mọi lệnh đọc ghi.



#***Hiểu về tx trong db
-> Transaction state có partially committed. 
Đây là trạng thái kiểu commit từng phần chứ kp toàn bộ trans. VD ta tạo 1 trans là A->B->C là chuyển tiền liên thông 3 người, thì A->B xong partially committed rồi B->C lại partially committed. 
=> Sau khi committed phần đầu tiên thì A được free và có thể sử dụng, còn lúc đang dùng sẽ bị lock lại. Sau khi committed 1 phần lần 1 thì nếu ROLLBACK về sau sẽ kp thực hiện lại từ đầu mà quay về lần partially committed cuối cùng thôi.

-> Transaction recovery:
Log file được tạo ra khi database được tạo, nó lưu thông tin actions để undo về sau. Bản chất nó k hoàn tác actions bằng cách thực hiện ngược lại mà lưu giá trị state tại thời điểm đó và cứ gán giá trị ngược về state cũ thôi. Các biến tạm sinh ra trong transaction cũng k cần lưu vào external mem, chỉ lưu trans state đổi như nào.
Log file or external mem chỉ được thực hiện lưu khi action flush log được thực hiện, flush sẽ ghi vào external mem, do đó các bước trước thất bại trước khi flush log thì nó chả làm gì cả.
VD khi trans bắt đầu thì viết vào lock file <start T>. Trạng thái hiện tại A đổi từ 8 thành 16 thì log file lưu <T, A, 8> mà k cần qt thực hiện như nào, chỉ biết A = 8 là trạng thái trước đó. 

--> Redo logging cần dùng nếu gặp sự cố như mất điện, hỏng ổ đĩa cần khôi phục các dữ liệu đã commit nhưng chưa kịp ghi lên data file thì sẽ update lại theo log. Nó bảo vệ tính toàn vẹn của dữ liệu.
Redo logging cũng chỉ là lưu giá trị mới VD <T, A, 16> 
Nó có thêm <commit T> là new state của database là consistency. Đây là trạng thái data xác nhận là được cập nhập dù trans có thể chưa thực hiện xong. Còn nếu có error, nó sẽ quay lại consistent state đã lưu chứ k quay lại từ đầu.

--> Khi undo logging, nó scan tất cả tìm mọi trans chưa hoàn thành để quay lại, tức là môi lần undo, nó sẽ undo mọi trans khác đi kèm mà chưa hoàn thành kể từ lúc cái trans sai này bắt đầu. Nó undo từng câu lệnh, sau khi xong thì viết aborted vào các trans vừa thực hiện xong. Do đó nếu file lớn thì làm rất lâu vì file xu hướng phình to dần => dùng <checkpoint> là để kbh search quá điểm này. 
Còn có <start ckpt(T1, T2)> là scan từ dưới lên và nó đảm bảo rằng T1, T2 chắc chắn đã hoàn thành bên trên, cho nên từ điểm start đến <end cpkt>, chỉ cần tìm các trans kp là T1, T2 là các giá trị cần được cập nhập.



# Transaction recovery
Quy tắc undo: mỗi khi undo 1 trans, nó sẽ undo mọi transaction mà chưa hoàn thành luôn. Nó search các trans chưa hoàn thành là các trans có start mà k có commit hoặc abort. 
Khi ghi, nó ghi log update trước khi update dữ liệu nhưng phải commit thực sự trước khi ghi log commit. Dùng disk
Redo cũng thực hiện tương tự nhưng ghi thêm END record vào cuối khi update flush vào disk, mỗi lần redo xong tất cả trans thì cũng ghi end vào và nhận biết trans chưa update bằng cách k có end ở cuối nhưng lại có commit. Commit ở đây chỉ báo là nó đáng ra là đã update trên database rồi, k có end tức là bị lỗi và phải redo lại cũng chỉ từ start đến commit ấy. Dùng main memory



#***Cách dùng IF NOT EXIST
CREATE TABLE IF NOT EXISTS -> Quá trình check và create table là 1tx
NOT EXIST cũng dùng trong condition bth

Lệnh insert if not exist, nếu id đã tồn tại thì update data, k thể thực hiện trong SQL trực tiếp. Buộc dùng phải dùng transaction thuần của sql:
BEGIN TRAN
  IF NOT EXISTS (SELECT 1 FROM [{scheme}].PowerPlatformConnection WITH (UPDLOCK,SERIALIZABLE) WHERE Id = @Id)
  BEGIN
    INSERT INTO [{scheme}].PowerPlatformConnection 
      (Id,TenantId)
    VALUES 
      (@Id,@TenantId)
  END
COMMIT TRAN

Mặc định cấp độ của DB là READ COMMITTED, nếu 2 giao dịch chạy đồng thời, tx1 chạy insert chưa committed, tx2 sẽ k thể đọc dữ liệu mới đó và vẫn pass qua if not exist và insert lần thứ 2. Giả sử k có unique key sẽ lỗi và 2 bản ghi sinh ra trùng nhau. Phải dùng UPDLock hoặc SERIALIZABLE 

Cơ chế UPDLock (hay update lock) cản lost update: Khi 1 câu lệnh sử dụng UPDLock, nó sẽ cản mọi tx khác update bản ghi đó, nó cũng cản lost update bằng cách không cho tx khác select nếu "đọc để update". Nó có tác dụng trong phạm vi các bản ghi bị lock. Vd update 1 bản ghi khác cùng bảng thì vẫn được. VD:
TxA:
BEGIN TRANSACTION;
SELECT value FROM MyTable WITH (UPDLOCK) WHERE id = 1; -- Đặt UPDLOCK trên bản ghi với id = 1
-- Giả sử giá trị hiện tại là 100
UPDATE MyTable SET value = 110 WHERE id = 1; -- Cập nhật giá trị
COMMIT;

TxB: 
BEGIN TRANSACTION;
SELECT value FROM MyTable WHERE id = 1; -- Đọc bản ghi với id = 1
-- Giao dịch B vẫn có thể đọc giá trị hiện tại (100 hoặc 110 tùy thuộc vào thời điểm)
COMMIT;

TxC:
BEGIN TRANSACTION;
SELECT value FROM MyTable WITH (UPDLOCK) WHERE id = 1; -- Đặt UPDLOCK trên bản ghi với id = 1
-- Giao dịch C sẽ bị chặn tại đây nếu Giao dịch A chưa hoàn tất
UPDATE MyTable SET value = 120 WHERE id = 1; -- Cập nhật giá trị
COMMIT;

=> Khi dùng khóa WITH ở bất cứ đâu trong 1 tx thực chất chỉ là nơi nó bắt đầu khóa thôi, sau đó nó sẽ khóa toàn bộ tx. VD ta dùng trong câu lệnh SELECT nhưng thực chất nó cả phần UPDATE, chỉ mở khóa sau khi tx được commit. 
Tức là VD đầu tiên WITH(UPDLOCK) là khóa hết tx khác can thiệp vào row đó, nên case đó chỉ cần dùng 1 trong 2 SERIALIZE hoặc UPDLOCK là đủ

-> Trong SQL mặc định khi truy vấn sẽ chặn các truy vấn khác trên cùng bảng cho đến khi hoàn thành để đảm bảo tính nhất quán. Ta có thể cản điều này với WITH(NOLOCK). 
VD: SELECT column1, column2 FROM tableName WITH (NOLOCK) WHERE someCondition
Cho nên khi ta tạo connection tới db trong C# với using, ta thấy không thể query được nếu connection đó chưa bị dispose 



## Database design:
Phần DB design có 2 pp: 
Top down: Entity Relational Schema <-> Relational Schema
Bottom up: Normalization


# ERD:
-> Vẽ ERD
--> Vẽ Entity-relationship diagram là vẽ mấy cái hộp hình thoi và hình chữ nhật nối với nhau biểu diễn quan hệ. Chuyển nó sang relational model là biểu diễn cái ER diagram sang các bảng thực tế, nối với nhau như nào, cái nào là primary key, ta dùng mapping process
Chú ý mỗi cái hình thoi nó là 1 bảng. Đọc đề phải hiểu rõ đề đang nói về thông tin của 1 bảng hay thông tin của 1 relationship. Phải xác định đúng quan hệ từng entity
Đề bài nói mơ hồ kiểu: mỗi Student chỉ làm việc trên 1 Project gây mơ hồ kiểu 1 Project có thể có nhiều Student không thì k rõ. Khi đó ta phải căn cứ vào nhiều dữ kiện đề bài và nếu cần tới mà k rõ có thể phải tự quy định điều đó. Tự làm theo ý mình thấy là đúng
Điểm khác biệt thứ 2 là khi vẽ ERD thì quan hệ many to many ta bd bình thường nhưng khi transfer sang relational model thì phải biểu diễn lại thành 2 cái cùng one-to-many cái action

--> Khi viết quan hệ, cố gắng viết chủ động, đừng viết action hình thoi là bị động
Khi đề bài cho ERClass thì thường là có 2 chiều, nếu k có 2 chiều mà là nói suông thì có thể đó chỉ là đoạn dẫn nhập

Khi design cái ERClass cần đảm bảo 1 bảng có primary key. Có thể nó map 1-1 với 1 bảng khác thì primary của nó có thể là trường mà nó dùng để ref đó nhưng quan trọng là nó phải có primary key. Nếu chuyển từ ERClass sang table phải tự thêm id cho nó. Khi vẽ ERClass cũng phải có primary key nếu cần ref, còn nếu dùng primary key từ 1 bảng khác thì có thể k cần ghi trường id cho bảng này

Kinh nghiệm vẽ ERD, nên nhớ relationship k cần vẽ là chứa id của cả 2 entity

-> Có nhiều loại atrributes khác nhau trong 1 entity set như stored, derived, single-valued, multi-valued, composite, simple/atomic attributes.
Để map từ ER sang relational thì tùy loại mà ta có thể dùng khác nhau:
Với strong entity thì ta lưu như bth entity là tên bảng và key của nó là primary key của bảng. Với weak entity thì nó thg có quan hệ với 1 strong entity khác thì bảng của nó có PK chứa PK của bảng strong entity. 

=> Entity relationship model chỉ là 1 cách biểu diễn khác, nó bd tốt hơn relational model vì có nhiều quan hệ hay. 

-> TH1: Người ta có thể chuyển đổi relationship giữa 2 entity có quan hệ m--n thành 1 entity mới. VD:
Subject n -- <teach> -- m Lecture 
thành: Subject 1 -- <taught> -- n Teaching n -- <teach> -- 1 Lecture
với attribute của relation teach thành attribute của entity Teaching
Khi biểu diễn như v thì attribute của Teaching ta k cần viết trên ERD có subID và LecID nữa vì quan hệ 1, n biểu diễn điều đó r-> 1 lưu ý khi vẽ oval attribute cho entity
Vd2: Client n -- <buy> -- m Product
thành: Client 1 -- have -- n Order n -- <is composed of> -- m Product
=> trong thực tế người ta thg chia ra nhiều bảng ra như v vì VD TH2 ta có thể biết 1 product được mua cùng những product nào trong Order vì có bảng riêng order sẽ lợi hơn. Cách 1 sẽ k thể hiện được nếu client mua lần 2 lần 3. khi đó buy sẽ phải có 1 trường quantity chẳng hạn

Th2: 1 entity có attribute multivalue cũng tách ra được
VD: Employee -> Child -> name, age
thành: Employee 1 -- <have> -- n Child -- name,age
-> K có employee vẫn vào được bảng child vì nó bị tách riêng chứ k còn là 1 thuộc tính của Employee nữa. Nếu cả bố và mẹ của child cùng là employee thì sẽ duplicate.

-> Khi JOIN 2 bảng mà k JOIN primary key thì có thể ra nhiều kết quả hơn bình thường.
R1(sid, age), R2(sportid, age) nếu ta JOIN age vào với nhau có thể ra môn sportid mà sid k chơi, cứ thêm 1 môn sport trùng age là lấy lại ra môn đó dù id k chơi

-> Toàn bị nhầm thứ tự về quan hệ số lượng: A n m B thì A 1 n X n 1 B
Kể cả A 1 n B ta cũng có A 1 n X n 1 B tức đều về 2 cái 1-n hết



#***Cách thiết kế quan hệ các bảng trong SQL
Với 1-1: C1 là bảng 1 có 1 id của bảng 2 hoặc ngược lại, C2 là 1 bảng mới chứa cả 2 id của bảng 1 và 2.
Với 1-n: C1 thì bắt buộc bảng n phải chứa identity của bảng 1, C2 là 1 bảng mới chứa PK của cả 2
Với n-m: Chỉ có 1 cách là 1 bảng mới chứa id của cả 2 bảng



# Functional dependency:
-> BT: Để chứng minh 1 FD từ nhiều FD, ta có thể cứ augmenting và reflexity nó lên tới full r tính tiếp với trans -> biến đổi dãy đó transitive cho nhau

-> F là 1 phủ của G nếu: mọi FD trong G đều thuộc F+ hay mọi FD trong G đều có thể inferred from F
Cụ thể: ta xét từng FD trong G và chứng minh nó nằm trong F+
-> F và G equivalent nếu: F là phủ của G và G là phủ của  F
VD: Prove that F = {A → C, AC → D, E → AD, E → H} and G = {A → CD, E → AH} are equivalent
• For each FD of F, prove that it is in G+ 
• A → C: (A)+(g) = ACD chứa C, so A → C thuộc G+ => Bởi vì A+ = ACD tức có A -> ACD thì C là tập con của ACD thì A chả suy ra được C còn gì. Ta cứ tìm closure của vế trái để ra được các thứ mà vế trái có thể infer ra
=> F+ thuộc G+
• For each FD of G, prove that it is in F+
(the same) => G+ thuộc F+
=> F+ = G+

-> Tìm minimal cover có bước cuối là check loại bỏ với transitive rule
FD là canonical form tức là form mà bên phải chỉ có 1 attribute
Các bước là: tách ra -> loại bỏ -> rút gọn cuối

-> Kinh nghiệm để xác định primary key thì mọi phần tử cx coi là 1 primary key và ta trừ dần các atts đi xem cái nào trừ được, k trừ được thì thôi
Kinh nghiệm xác định functional dependency(là quan hệ phụ thuộc ->):
Định luật armstrong cho phép biến đổi các FD qua lại lẫn nhau, nhờ nó mà tìm ra nhiều FD và ta cần chọn ra FD phù hợp.
Với các atts bên phải ta loại trừ dần vì nó phụ thuộc vào các atts bên trái mà bên trái mà có thì sẽ refer được tới cái bên phải. Nếu cái nào k xh bên phải thì nó buộc là part of key
VD: A->BC, CD->E và ABCDE thì bên phải ta loại dần là loại E vì CD có r xong ta loại BC và A có rồi thì còn AD k loại được nx nên AD làm minimal key
=> vc change order của vc loại trừ dần các key khác nhau có thể tạo ra nhiều minimal key cho 1 FDs

Pro: VD quan hệ 1-1 teacher và class với quan hệ teacher dạy class đó. Ta k nên làm kiểu classID là foreign key của teacher mà nên dùng teacher làm foreign key của classID sẽ tốt hơn vì 1 class buộc có ít nhất 1 người manager quan lý nó chứ 1 teacher có thể k dạy class nào
Nói 1 cách khó hiêu hơn thì teacher -> class tức 1 class chỉ được xác định khi có teacher vì k có trường teacher thì k xác định được 1 row mà. Hay: X->Y thì X>Y hay Y là tập con của X và số phần tử của X >= số phần tử của Y
Còn quan hệ 1-many thì buộc dùng 1 chiều chứ k được lựa chọn như trên.

-> Có 3 kiểu FD: full, partial và transitive
Transitive là kiểu A->B->C thì A->C là 1 transtive FD tạo từ 2 FD kia

A->B nó cũng giống như định nghĩa ánh xạ bình thường, k có 2 A trùng nhau nhưng B thì có nên |B| <= |A|

-> closure of F: giả sử F là 1 FD thì các FD khác suy ra được từ F dựa vào các định lý bth gọi là closure of F, là F+
closure of a set of attribute based on F: là X+ là set of attribute xác định từ X bởi F. Vd F có A->B thì X là (A) thì X+ là (AB) vì B suy ra được từ A. Có dạng bài cho tìm cái này. Để check 1 cái có thuộc closure của F hay k ta cũng cứ tìm X+ của vế trái là ra. 
Có nhiều dạng bài viết liên quan đến FD.

Để tìm closure function, xuất phát từ 1 cục X -> lấy từng dependency trong F nếu vế trái là tập con của X thì X U= vế phải

Nếu nói F={A->CD, E->AH} thì F+ là (A)+ U (E)+ 

AB -> C thì AB -> ABC được



#***Thiết kế database cho multi-tenancy
Giả sử ta cần tạo ứng dụng cung cấp cho nhiều tổ chức, khách hàng khác nhau. Ta cần quản lý sao cho mỗi tổ chức có 1 cục data riêng và k sử dụng conflict của nhau, đảm bảo security. Có 3 kiến trúc:
1) Single db for single tenant
Mỗi tổ chức có 1 database khác nhau.
Tính linh hoạt cao. Vd 1 tổ chức yêu cầu mã hóa dữ liệu, 1 tổ chức thì không, ta có thể dễ dàng làm được nhờ tách độc lập chúng; Tính bảo mật cao, phân quyền tốt. VD ta có thể cho tk admin của từng tenant chỉ được truy cập vào các db tương ứng.
=> Tuy nhiên chi phí sẽ rất tốn kém, phù hợp với các ứng dụng rất lớn. VD untrest dùng cái này

2) Separate schema for each tenant
Tất cả tổ chức dùng chung 1 database cho 1 ứng dụng. Trong database có vô số table nhưng phân biệt table của các tenant khác nhau bằng schema. 
Bảo mật kém hơn nhưng chi phí rẻ hơn. Quản lý dễ dàng vì gói gọn trong 1 database.
Nếu số lượng tổ chức tăng cao, database sẽ có quá nhiều table, khó mở rộng và quản lý

3) Shared schame for tenants
Đây là cách dễ nhất và chỉ phù hợp với các ứng dụng nhỏ. Tất cả dùng chung db và table nhưng phân biệt giữa các tenant thông qua 1 trường là tenant id. 
Bảo mật thấp vì chung 1 database; K linh hoạt, query phức tạp hơn để lấy hay update data của riêng 1 tenant. Khó khăn trong quản lý, cập nhật, mở rộng.


